# Mitigating Hallucinations in Medical QA via Neuro-Symbolic RAG

##  Overview
This project addresses the issue of "hallucinations" in Large Language Models (LLMs) within the high-stakes medical domain. By implementing a **Neuro-Symbolic Retrieval-Augmented Generation (RAG)** system, we combine the reasoning capabilities of Knowledge Graphs (Symbolic) with the retrieval efficiency of Vector Search (Neural) to improve the faithfulness of answers generated by **Gemma-2b**.

##  Key Features & Methodology
We implemented and compared three distinct architectures to answer expert-labeled questions from the **PubMedQA** dataset:

### 1. Basic RAG (Baseline)
- Uses **FAISS** vector search with `all-mpnet-base-v2` embeddings.
- Retrieves top-k text chunks based purely on semantic similarity.

### 2. Advanced Graph RAG (Neuro-Symbolic)
- **Knowledge Injection:** Uses **Gemma-2b** to extract structured triplets (`Subject` -> `Relation` -> `Object`) from medical abstracts.
- **Graph Construction:** Builds a dynamic Knowledge Graph using **NetworkX**.
- **Cross-Encoder Re-Ranking:** Validates retrieved contexts using a "Judge" model (`ms-marco-MiniLM-L-6-v2`) to filter irrelevant information.

### 3. Production System (Hybrid Cascading)
- A robust pipeline that prioritizes precision.
- Attempts the **Advanced Graph RAG** first.
- If the Re-Ranker rejects the context (low confidence), it **falls back** to the Basic RAG system to ensure an answer is provided without compromising initial strictness.

##  Tech Stack
- **LLM:** Google `gemma-2b-it` (4-bit quantization via `bitsandbytes`)
- **Orchestration:** `transformers`, `accelerate`, `torch`
- **Vector Database:** `faiss-cpu`
- **Knowledge Graph:** `networkx`, `matplotlib`
- **Embeddings:** `sentence-transformers`
- **Dataset:** `pubmed_qa`

## Contributors
- Alireza Shahidiani
- Omid Nejati
- Gita Javadi
